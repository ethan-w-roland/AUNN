{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def positional_encoding(x: torch.Tensor, dim: int = 64):\n",
    "    \"\"\"Apply fourier positional encoding to the input.\n",
    "\n",
    "    Args:\n",
    "      x (torch.Tensor): a 1 dimension tensor of indices\n",
    "      dim (optional, int): dimension of positional encoding. max index representable is 2^(dim//2+1). Default: 64.\n",
    "    Returns:\n",
    "      (torch.Tensor): Positional encoding of the input tensor. dimension: [x.size(0), dim]\n",
    "    \"\"\"\n",
    "    position = x.unsqueeze(1)\n",
    "    device = x.device  # Get the device of x\n",
    "\n",
    "    # Create div_term on the same device as x\n",
    "    div_term = torch.exp(\n",
    "        torch.arange(0, dim, 2, dtype=torch.float32, device=device) *\\\n",
    "            (-np.log(10000.0) / dim)\n",
    "    )\n",
    "\n",
    "    # Create pe on the same device as x\n",
    "    pe = torch.zeros(x.size(0), dim, device=device)\n",
    "\n",
    "    # Perform computations\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)\n",
    "    return pe\n",
    "'''\n",
    "\n",
    "'''\n",
    "def positional_encoding(x:torch.tensor, dim:int=64):\n",
    "    \"\"\"Apply fourier positional encoding to the input.\n",
    "\n",
    "    Args:\n",
    "      x (torch.Tensor): a 1 dimension tensor of indices\n",
    "      dim (optional, int): dimension of positional encoding. max index representable is 2^(dim//2+1). Default: 64.\n",
    "    Returns:\n",
    "      (torch.Tensor): Positional encoding of the input tensor. dimension: [x.size(0), dim]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    # encode input tensor and append the encoded tensor to the list of results.\n",
    "    for i in range(dim//2):\n",
    "        freq = 2 ** (i+1) #add 2 bc freq<4 is uninformative\n",
    "        x_mod_freq = x % freq\n",
    "        for func in [torch.sin, torch.cos]:\n",
    "            result = func(2 * torch.pi * x_mod_freq / freq)\n",
    "            results.append(result)\n",
    "    return torch.stack(results, dim=-1)\n",
    "'''\n",
    "    \n",
    "def positional_encoding(x: torch.Tensor, dim: int = 48):\n",
    "    \"\"\"\n",
    "    Binary positional encoding, where each dimension is a bit in the binary representation of the index.\n",
    "    \n",
    "    Args:\n",
    "        x (torch.Tensor): Input tensor of positions with shape [N]\n",
    "        dim (int): Number of bits in the binary encoding (output dimension). Default is 48.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A binary encoding tensor with shape [N, dim] where each bit represents a binary position.\n",
    "    \"\"\"\n",
    "    # Ensure x is an integer tensor for binary conversion\n",
    "    x = x.to(torch.int64)\n",
    "\n",
    "    # Create a tensor for binary representation\n",
    "    # Each row corresponds to an element in x; columns are the binary bits\n",
    "    encoding = ((x.unsqueeze(1) >> torch.arange(dim, device=x.device)) & 1).to(torch.float32)\n",
    "    \n",
    "    # Flip the encoding to match the conventional binary order (most significant bit on the left)\n",
    "    encoding = encoding.flip(dims=[1])\n",
    "\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUNNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, output_dim, num_layers, hidden_dim):\n",
    "        super(AUNNModel, self).__init__()\n",
    "        assert embedding_dim % 2 == 0, \"Embedding dimension must be even.\"\n",
    "        assert num_layers % 2 == 0 and num_layers >= 2, \"Number of layers must be even and at least 2.\"\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Input Layer\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.RMSNorm(self.hidden_dim)\n",
    "        )\n",
    "\n",
    "        # Hidden Layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(self.num_layers - 2):  # Exclude input and output layers\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                nn.RMSNorm(self.hidden_dim)\n",
    "            ))\n",
    "\n",
    "        # Output Layer\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # He initialization for Swish activation\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.input_layer(x)\n",
    "        residual = output  # Initialize residual for skip connections\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            output = layer(output)\n",
    "\n",
    "            # Apply skip connection every two layers\n",
    "            if (idx + 1) % 2 == 0:\n",
    "                output = output + residual  # Skip connection\n",
    "                residual = output  # Update residual\n",
    "\n",
    "        output = self.output_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "embedd_dim = 64\n",
    "num_layers = 4      # Must be even and at least 2 (bc of skip connections)\n",
    "hidden_dim = 128    # Size of hidden layers\n",
    "batch_size = 8192  # Adjust batch size for efficiency\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#really long repeated pattern\n",
    "'''\n",
    "text = \"abc\" * 10_000  # Repeat the sequence to create a long string\n",
    "'''\n",
    "\n",
    "#really long random pattern\n",
    "options = ['|aaa','|bbb','|ccc']\n",
    "num_sequences = 15_000\n",
    "num_repeats = num_sequences * len(options)\n",
    "num_repeats = num_repeats - num_repeats % batch_size # ensure num_repeats is a multiple of batch_size\n",
    "options = options * num_repeats\n",
    "random.seed(42)\n",
    "random.shuffle(options)\n",
    "text = ''.join(options)\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))\n",
    "token_to_id = {token: id for id, token in enumerate(vocab)}\n",
    "id_to_token = {id: token for token, id in token_to_id.items()}\n",
    "token_ids = [token_to_id[char] for char in text]\n",
    "token_ids = torch.tensor(token_ids, dtype=torch.long).to(device)\n",
    "positions = torch.arange(len(token_ids), dtype=torch.float32)\n",
    "embeds = positional_encoding(positions, embedd_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = AUNNModel(embedd_dim, len(vocab), num_layers, hidden_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "losses = []\n",
    "accuracies = []\n",
    "total_steps = len(text) // batch_size\n",
    "if len(text) % batch_size != 0:\n",
    "    total_steps += 1\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    start_idxs = list(range(0, len(text), batch_size))\n",
    "    # random.seed(epoch)\n",
    "    # random.shuffle(start_idxs)\n",
    "    for start_idx in start_idxs:\n",
    "        end_idx = start_idx + batch_size\n",
    "        \n",
    "        inputs = embeds[start_idx:end_idx]\n",
    "        targets = token_ids[start_idx:end_idx]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cur_loss = loss.item()\n",
    "        losses.append(cur_loss)\n",
    "\n",
    "        #calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == targets).sum().item()\n",
    "        cur_acc = correct / batch_size\n",
    "        accuracies.append(cur_acc)\n",
    "        \n",
    "\n",
    "    avg_loss = sum(losses[-len(start_idxs):]) / len(start_idxs)\n",
    "    avg_acc = sum(accuracies[-len(start_idxs):]) / len(start_idxs)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] completed, Average Loss: {avg_loss:.6f}, Average Accuracy: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.figure(figsize=(40, 6))\n",
    "plt.plot(losses[::], label=\"Training Loss\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the accuracy curves\n",
    "plt.figure(figsize=(40, 6))\n",
    "plt.plot(accuracies[::], label=\"Training Accuracy\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Text Function\n",
    "def generate_text(model, start_index, length):\n",
    "    model.eval()\n",
    "    generated_tokens = []\n",
    "    indices = np.arange(start_index, start_index + length)\n",
    "    x = torch.tensor(indices, dtype=torch.float32).to(device)\n",
    "    inputs = positional_encoding(x, embedd_dim).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    for id in predicted:\n",
    "        token = id_to_token.get(id.item(), \"<UNK>\")\n",
    "        generated_tokens.append(token)\n",
    "    return ''.join(generated_tokens)\n",
    "\n",
    "# Generate text starting from the next index after the training data\n",
    "start_index = 0\n",
    "generated_text = generate_text(model, start_index=start_index, length=100)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text)\n",
    "\n",
    "# Generate text starting from the next index after the training data\n",
    "start_index = len(text)\n",
    "generated_text = generate_text(model, start_index=start_index, length=100)\n",
    "print(\"Generated Text:\")\n",
    "print(generated_text) #learns underlying pattern & generalizes to unseen indices :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(text) - 1\n",
    "preds = generate_text(model, start_index=N+1, length=50_000)\n",
    "count = {}\n",
    "for char in preds:\n",
    "    count[char] = count.get(char, 0) + 1\n",
    "\n",
    "plt.bar(count.keys(), count.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the accuracy of the model on the dataset via random sample of 100k characters\n",
    "import random\n",
    "\n",
    "# Number of samples\n",
    "num_samples = 100_000\n",
    "\n",
    "# Randomly select indices from the dataset\n",
    "sample_indices = random.sample(range(len(text)), num_samples)\n",
    "\n",
    "# Get positions and targets for the sampled indices\n",
    "inputs = []\n",
    "outputs = []\n",
    "for idx in sample_indices:\n",
    "    inp = embeds[idx]\n",
    "    inputs.append(inp)\n",
    "    output = token_ids[idx]\n",
    "    outputs.append(output)\n",
    "\n",
    "# Concatenate the inputs and outputs\n",
    "inputs = torch.stack(inputs).to(device)\n",
    "outputs = torch.stack(outputs).to(device)\n",
    "\n",
    "# Get model predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(inputs)\n",
    "    _, predicted = torch.max(predictions, 1)\n",
    "    \n",
    "# Calculate accuracy\n",
    "correct = (predicted == outputs).sum().item()\n",
    "accuracy = correct / num_samples\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to save the model checkpoint\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved at epoch {epoch} with loss {loss:.4f}\")\n",
    "\n",
    "save_checkpoint(model, optimizer, epoch+1, avg_loss, filename=f\"sequence/checkpoint_epoch_{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth\"):\n",
    "    checkpoint = torch.load(filename, weights_only=True)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded: epoch {epoch}, loss {loss:.4f}\")\n",
    "    return epoch, loss\n",
    "\n",
    "model = AUNNModel(embedd_dim, len(vocab), num_layers, hidden_dim).to(device)\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "start_epoch, start_loss = load_checkpoint(model, optimizer, filename=\"sequence/checkpoint_epoch_500.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Example usage\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(text) - 1\n",
    "\n",
    "#see value before conditioning\n",
    "generated_text = generate_text(model, start_index=N+1, length=150)\n",
    "print(\"Original Text:\")\n",
    "print(generated_text) # \"|a...\"\n",
    "print(\"\")\n",
    "\n",
    "#conditioning the model\n",
    "conditioning_targets = ['c','a','b']  # Desired tokens at N+1 and N+2, this also works if you use \"|b\"\n",
    "conditioning_positions = [N+2, N+7, N+12]\n",
    "\n",
    "conditioning_target_indices = [token_to_id[token] for token in conditioning_targets]\n",
    "positions_tensor = torch.tensor(conditioning_positions, dtype=torch.float32).to(device)\n",
    "targets_tensor = torch.tensor(conditioning_target_indices, dtype=torch.long).to(device)\n",
    "inputs = positional_encoding(positions_tensor, embedd_dim).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "conditioning_optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "model.train()\n",
    "num_conditioning_steps = 10\n",
    "\n",
    "for step in range(num_conditioning_steps):\n",
    "    conditioning_optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets_tensor)\n",
    "    loss.backward()\n",
    "    conditioning_optimizer.step()\n",
    "    print(f\"Conditioning Step {step+1}/{num_conditioning_steps}, Loss: {loss.item():.6f}\")\n",
    "\n",
    "#see value after conditioning\n",
    "generated_text = generate_text(model, start_index=N+1, length=150)\n",
    "print(\"\")\n",
    "print(\"Text after conditioning:\")\n",
    "print(generated_text) # \"|ccc|...\" shows conditioning works because of N+3 and N+4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
