{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Classification / Generation using AUNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "#deallocate all cuda memory\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#print cuda memory\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def positional_encoding(x: torch.Tensor, dim: int = 96):\n",
    "#     \"\"\"Apply fourier positional encoding to the input.\n",
    "\n",
    "#     Args:\n",
    "#       x (torch.Tensor): a 1 dimension tensor of indices\n",
    "#       dim (optional, int): dimension of positional encoding. max index representable is 2^(dim//2+1). Default: 64.\n",
    "#     Returns:\n",
    "#       (torch.Tensor): Positional encoding of the input tensor. dimension: [x.size(0), dim]\n",
    "#     \"\"\"\n",
    "#     position = x.unsqueeze(1)\n",
    "#     device = x.device  # Get the device of x\n",
    "\n",
    "#     # Create div_term on the same device as x\n",
    "#     base = 10_000_000.0\n",
    "#     div_term = torch.exp(\n",
    "#         torch.arange(0, dim, 2, dtype=torch.float32, device=device) *\\\n",
    "#             (-np.log(base) / dim)\n",
    "#     )\n",
    "\n",
    "#     # Create pe on the same device as x\n",
    "#     pe = torch.zeros(x.size(0), dim, device=device)\n",
    "\n",
    "#     # Perform computations\n",
    "#     pe[:, 0::2] = torch.sin(position * div_term)\n",
    "#     pe[:, 1::2] = torch.cos(position * div_term)\n",
    "#     return pe\n",
    "\n",
    "\n",
    "def positional_encoding(x, dim: int = 48):\n",
    "    \"\"\"\n",
    "    Binary positional encoding, where each dimension is a bit in the binary representation of the index.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor of positions with shape [N]\n",
    "        dim (int): Number of bits in the binary encoding (output dimension). Default is 48.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A binary encoding tensor with shape [N, dim] where each bit represents a binary position.\n",
    "    \"\"\"\n",
    "\n",
    "    # Each row corresponds to an element in x; columns are the binary bits\n",
    "    encoding = ((x.unsqueeze(1) >> torch.arange(dim, device=x.device)) & 1).to(torch.float32)\n",
    "\n",
    "    return encoding\n",
    "\n",
    "\n",
    "# def positional_encoding(x: torch.Tensor, dim: int = 48):\n",
    "#     \"\"\"\n",
    "#     Positional encoding using sine and cosine functions with frequencies as powers of two,\n",
    "#     starting from 2^2 (i.e., skipping 2^0 and 2^1).\n",
    "\n",
    "#     Args:\n",
    "#         x (torch.Tensor): Input tensor of positions with shape [N]\n",
    "#         dim (int): Total dimension of the encoding. Must be even.\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: A tensor with shape [N, dim] containing the positional encodings.\n",
    "#     \"\"\"\n",
    "#     assert dim % 2 == 0, \"Encoding dimension (dim) must be even.\"\n",
    "\n",
    "#     # Frequencies corresponding to powers of two, starting from 2^1\n",
    "#     frequency_powers = torch.arange(0, dim, dtype=torch.float32, device=x.device)\n",
    "#     frequencies = 2 ** frequency_powers  # Shape: [num_frequencies]\n",
    "\n",
    "#     # Compute the angles: [N, num_frequencies]\n",
    "#     x = x.unsqueeze(1)  # Shape: [N, 1]\n",
    "#     angles = (2 * torch.pi * x) / frequencies  # Broadcasting over x and frequencies\n",
    "\n",
    "#     # Compute the positional encodings\n",
    "#     encoding = torch.sin(angles)\n",
    "\n",
    "#     return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AUNNModel(nn.Module):\n",
    "    def __init__(self, embedding_dim:int, output_dim:int, num_layers:int, hidden_dim:int):\n",
    "\n",
    "        super(AUNNModel, self).__init__()\n",
    "        \n",
    "        assert num_layers % 2 == 0 and num_layers >= 2, \"Number of layers must be even and at least 2.\"\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Input Layer\n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            # nn.RMSNorm(self.hidden_dim)\n",
    "        )\n",
    "\n",
    "        # Hidden Layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(self.num_layers - 2):  # Exclude input and output layers\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "                nn.SiLU(),\n",
    "                # nn.RMSNorm(self.hidden_dim)\n",
    "            ))\n",
    "\n",
    "        # Output Layer\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                # He initialization for Swish activation\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        output = self.input_layer(x)\n",
    "        residual = output  # Initialize residual for skip connections\n",
    "\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            output = layer(output)\n",
    "\n",
    "            # Apply skip connection every two layers\n",
    "            if (idx + 1) % 2 == 0:\n",
    "                output = output + residual  # Skip connection\n",
    "                residual = output  # Update residual\n",
    "\n",
    "        output = self.output_layer(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to save the model checkpoint\n",
    "def save_checkpoint(model, params, optimizer, losses, filename=\"checkpoint.pth\"):\n",
    "    \n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'losses': losses,\n",
    "    }\n",
    "\n",
    "    keys = ['embedding_dim', 'output_dim', 'num_layers', 'hidden_dim']\n",
    "    assert all(k in params for k in keys)\n",
    "    for k in keys:\n",
    "        checkpoint[k] = params[k]\n",
    "\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved with loss {losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filename=\"checkpoint.pth\"):\n",
    "\n",
    "    checkpoint = torch.load(filename, weights_only=True)\n",
    "    \n",
    "    keys = ['embedding_dim', 'output_dim', 'num_layers', 'hidden_dim']\n",
    "    params = {k: checkpoint[k] for k in keys}\n",
    "    \n",
    "    model = AUNNModel(**params)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    losses = checkpoint['losses']\n",
    "\n",
    "    print(f\"Checkpoint loaded: loss {losses[-1]:.4f}\")\n",
    "\n",
    "    return model, optimizer, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "from array import array\n",
    "\n",
    "def load_mnist(images_path, labels_path, shuffle=False, seed=42):\n",
    "\n",
    "    labels = []\n",
    "    with open(labels_path, 'rb') as file:\n",
    "        magic, size = struct.unpack(\">II\", file.read(8)) \n",
    "        if magic != 2049:\n",
    "            raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "        labels = array(\"B\", file.read())\n",
    "\n",
    "    images = []\n",
    "    rows, cols = None, None\n",
    "    with open(images_path, 'rb') as file:\n",
    "        magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "        data = array(\"B\", file.read())\n",
    "        for i in range(size):\n",
    "            img = np.array(data[i * rows * cols:(i + 1) * rows * cols], dtype=np.uint8)\n",
    "            img = np.where(img > 0, 1, 0) #binarize\n",
    "            img.resize((rows, cols))\n",
    "            images.append(img)\n",
    "\n",
    "    assert len(images) == len(labels)\n",
    "\n",
    "    if shuffle:\n",
    "        random.seed(seed)\n",
    "        indices = list(range(len(images)))\n",
    "        random.shuffle(indices)\n",
    "        images = [images[i] for i in indices]\n",
    "        labels = [labels[i] for i in indices]\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "cur_dir = Path().resolve()\n",
    "input_path = cur_dir / 'mnist'\n",
    "training_images_filepath = input_path / 'train-images.idx3-ubyte'\n",
    "training_labels_filepath = input_path /'train-labels.idx1-ubyte'\n",
    "test_images_filepath = input_path / 't10k-images.idx3-ubyte'\n",
    "test_labels_filepath = input_path / 't10k-labels.idx1-ubyte'\n",
    "\n",
    "images, labels = load_mnist(training_images_filepath, training_labels_filepath, shuffle=True, seed=0)\n",
    "\n",
    "label2idx = {}\n",
    "for idx, label in enumerate(labels):\n",
    "    if label not in label2idx:\n",
    "        label2idx[label] = []\n",
    "    label2idx[label].append(idx)\n",
    "\n",
    "img_size = len(images[0].flatten())\n",
    "\n",
    "plt.imshow(images[0], cmap='gray')\n",
    "plt.show()\n",
    "print(labels[0])\n",
    "print(img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "embedd_dim = 48\n",
    "num_layers = 8     # Must be even and at least 2 (bc of skip connections)\n",
    "hidden_dim = 512  # Size of hidden layers\n",
    "output_dim = 2\n",
    "\n",
    "eos_bos_len = 8\n",
    "label_len = 10\n",
    "entry_length = eos_bos_len * 2 + label_len * 2 + img_size\n",
    "assert entry_length < 1024, \"Entry length must be less than 1024, improves positional encoding consistency.\"\n",
    "print(entry_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = AUNNModel(embedd_dim, output_dim, num_layers, hidden_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Example Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "img_per_label = 1\n",
    "example_imgs = {}\n",
    "for label in train_labels:\n",
    "    print(label)\n",
    "    example_imgs[label] = []\n",
    "    for idx in label2idx[label][:img_per_label]:\n",
    "        img = images[idx]\n",
    "        example_imgs[label].append(img)\n",
    "        plt.figure(figsize=(2,2))\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_provider(num_epochs, num_entries, batch_size=64, seed=42, offset_entries=0):\n",
    "\n",
    "    assert num_entries % batch_size == 0, \"Number of entries must be divisible by batch size.\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    N = offset_entries\n",
    "\n",
    "    #instantiate sequence\n",
    "\n",
    "    labels = []\n",
    "    for _ in range(num_entries):\n",
    "        label = random.choice(train_labels)\n",
    "        labels.append(label)\n",
    "        \n",
    "    variants = []\n",
    "    for _ in range(num_entries):\n",
    "        variant = random.choice(list(range(img_per_label)))\n",
    "        variants.append(variant)\n",
    "\n",
    "    print(f\"Labels: {labels[:5]}\")\n",
    "        \n",
    "    for label, variant in zip(labels, variants):\n",
    "\n",
    "        #add a begin sequence indicator (8 ones in a row)\n",
    "        begin_sequence = torch.ones(eos_bos_len, dtype=torch.uint8)\n",
    "        targets.append(begin_sequence)\n",
    "\n",
    "        #one hot encode the label\n",
    "        label_data = torch.zeros(label_len, dtype=torch.uint8)\n",
    "        label_data[label] = 1\n",
    "        targets.append(label_data)\n",
    "\n",
    "        #add image to inputs\n",
    "        img_data = example_imgs[label][variant]\n",
    "        img_data = img_data.flatten()\n",
    "        img_data = torch.tensor(img_data, dtype=torch.uint8)\n",
    "        targets.append(img_data)\n",
    "\n",
    "        #add the label again\n",
    "        label_data = torch.zeros(label_len, dtype=torch.uint8)\n",
    "        label_data[label] = 1\n",
    "        targets.append(label_data)\n",
    "\n",
    "        #add an end sequence indicator (8 ones in a row)\n",
    "        end_sequence = torch.ones(eos_bos_len, dtype=torch.uint8)\n",
    "        targets.append(end_sequence)\n",
    "\n",
    "        #make input embedding\n",
    "        start = N * 1024\n",
    "        index = torch.arange(start, start + entry_length)\n",
    "        embed = positional_encoding(index, embedd_dim)\n",
    "        inputs.append(embed)\n",
    "        N += 1\n",
    "\n",
    "    inputs = torch.cat(inputs, dim=0)\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    targets = torch.cat(targets, dim=0)\n",
    "    targets = targets.to(device)\n",
    "\n",
    "    print(f\"Total Indices: {len(inputs)}\")\n",
    "\n",
    "    num_batches = num_entries // batch_size\n",
    "    batch_indices = list(range(num_batches))\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "        random.shuffle(batch_indices)\n",
    "\n",
    "        for batch_idx in batch_indices:\n",
    "\n",
    "            start = batch_idx * batch_size * entry_length\n",
    "            end = (batch_idx + 1) * batch_size * entry_length\n",
    "\n",
    "            yield epoch+1, inputs[start:end], targets[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10_000\n",
    "num_entries = 200\n",
    "batch_size = 100\n",
    "offset = 0\n",
    "num_batches = num_entries // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "print(\"Initializing training loop...\")\n",
    "print(f\"Number of entries: {num_entries}, Batch size: {batch_size}, Number of batches: {num_batches}\")\n",
    "\n",
    "model.train()\n",
    "\n",
    "last_epoch = 1\n",
    "epoch_losses = []\n",
    "batch_num = 0\n",
    "\n",
    "for epoch, inputs, targets in data_provider(num_epochs=num_epochs, num_entries=num_entries, batch_size=batch_size, offset_entries=offset):\n",
    "    \n",
    "    if epoch != last_epoch: # epoch logging\n",
    "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch [{last_epoch}/{num_epochs}] completed, Loss: {avg_loss:.8f}\")\n",
    "        batch_num = 0\n",
    "        epoch_losses = []\n",
    "        last_epoch = epoch\n",
    "        \n",
    "    batch_num += 1\n",
    "    \n",
    "    # do optimization\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if loss != loss:\n",
    "        print(\"ERR loss is NaN\")\n",
    "\n",
    "    cur_loss = loss.item()\n",
    "    epoch_losses.append(cur_loss)\n",
    "\n",
    "    if batch_num % 10 == 0 and batch_num != num_batches: # batch logging\n",
    "        print(f\"Epoch [{last_epoch}/{num_epochs}], Batch [{batch_num}/{num_batches}], Loss: {cur_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_output(start_idx):\n",
    "    model.eval()\n",
    "    indices = torch.arange(start_idx, start_idx+entry_length).to(device)\n",
    "    inputs = positional_encoding(indices, embedd_dim)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    predicted = predicted.cpu().numpy()\n",
    "    start = 0\n",
    "    bos = predicted[start:start+eos_bos_len]\n",
    "    start += eos_bos_len\n",
    "    label = predicted[start:start+label_len]\n",
    "    start += label_len\n",
    "    img = predicted[start:start+img_size]\n",
    "    img = img.reshape(28, 28)\n",
    "    start += img_size\n",
    "    label2 = predicted[start:start+label_len]\n",
    "    start += label_len\n",
    "    eos = predicted[start:start+eos_bos_len]\n",
    "    print(\"BOS:\", bos)\n",
    "    print(\"Label:\", label)\n",
    "    print(\"Image:\", img)\n",
    "    print(\"Label2:\", label2)\n",
    "    print(\"EOS:\", eos)\n",
    "    \n",
    "# start = offset\n",
    "# start = num_entries + offset\n",
    "start = 600\n",
    "num_to_show = 100\n",
    "\n",
    "for entry_idx in range(start, start+num_to_show):\n",
    "    seq_start = entry_idx * 1024\n",
    "    print(f\"Sequence @ {entry_idx}, idx = {seq_start}\")\n",
    "    eval_output(seq_start)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoint\n",
    "save_checkpoint(\n",
    "    model, \n",
    "    {'embedding_dim': embedd_dim, 'output_dim': output_dim, 'num_layers': num_layers, 'hidden_dim': hidden_dim}, \n",
    "    optimizer, \n",
    "    losses, \n",
    "    filename=\"mnist/checkpoint_scaffold_10x1.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Example Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, losses = load_checkpoint(filename=\"mnist/checkpoint_scaffold_10x1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [0,1,2,3,4,5,6,7,8,9]\n",
    "img_per_label = 100\n",
    "example_imgs = {}\n",
    "for label in train_labels:\n",
    "    print(label)\n",
    "    example_imgs[label] = []\n",
    "    for idx in label2idx[label][:img_per_label]:\n",
    "        img = images[idx]\n",
    "        example_imgs[label].append(img)\n",
    "        # plt.figure(figsize=(2,2))\n",
    "        # plt.imshow(img, cmap='gray')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10_000\n",
    "num_entries = 5000\n",
    "batch_size = 100\n",
    "offset = 0\n",
    "num_batches = num_entries // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "print(\"Initializing training loop...\")\n",
    "print(f\"Number of entries: {num_entries}, Batch size: {batch_size}, Number of batches: {num_batches}\")\n",
    "\n",
    "model.train()\n",
    "\n",
    "last_epoch = 1\n",
    "epoch_losses = []\n",
    "batch_num = 0\n",
    "\n",
    "for epoch, inputs, targets in data_provider(num_epochs=num_epochs, num_entries=num_entries, batch_size=batch_size, offset_entries=offset):\n",
    "    \n",
    "    if epoch != last_epoch: # epoch logging\n",
    "        avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "        losses.append(avg_loss)\n",
    "        print(f\"Epoch [{last_epoch}/{num_epochs}] completed, Loss: {avg_loss:.8f}\")\n",
    "        batch_num = 0\n",
    "        epoch_losses = []\n",
    "        last_epoch = epoch\n",
    "        \n",
    "    batch_num += 1\n",
    "    \n",
    "    # do optimization\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if loss != loss:\n",
    "        print(\"ERR loss is NaN\")\n",
    "\n",
    "    cur_loss = loss.item()\n",
    "    epoch_losses.append(cur_loss)\n",
    "\n",
    "    if batch_num % 10 == 0 and batch_num != num_batches: # batch logging\n",
    "        print(f\"Epoch [{last_epoch}/{num_epochs}], Batch [{batch_num}/{num_batches}], Loss: {cur_loss:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss curves\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.plot(losses, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = offset\n",
    "start = num_entries + offset\n",
    "num_to_show = 100\n",
    "\n",
    "for entry_idx in range(start, start+num_to_show):\n",
    "    seq_start = entry_idx * 1024\n",
    "    print(f\"Sequence @ {entry_idx}, idx = {seq_start}\")\n",
    "    eval_output(seq_start)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save checkpoint\n",
    "save_checkpoint(\n",
    "    model, \n",
    "    {'embedding_dim': embedd_dim, 'output_dim': output_dim, 'num_layers': num_layers, 'hidden_dim': hidden_dim}, \n",
    "    optimizer, \n",
    "    losses, \n",
    "    filename=\"mnist/checkpoint_scaffold_10x100.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
